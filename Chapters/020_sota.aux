\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{LeCun.1989}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Related Work}{3}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lst}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{lst}{\addvspace {10\p@ }}
\newlabel{State of the art}{{2}{3}{Related Work}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Convolutional Neural Networks (CNNs)}{3}{section.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example Images from the ImageNet dataset.}}{4}{figure.caption.8}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:ImageNet}{{2.1}{4}{Example Images from the ImageNet dataset}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}ImageNet}{4}{subsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}U-Net Architecture}{5}{subsection.2.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Schematic illustration of the U-Net architecture for image segmentation. The network consists of a contracting path (left side) to capture context via successive convolutional (3×3, ReLU) and max pooling (2×2) operations, and an expansive path (right side) that enables precise localization through up-convolutions (2×2) and concatenation with high-resolution features from the contracting path. The final segmentation map is generated using a 1×1 convolution. Feature map sizes and channel numbers are indicated for each layer.}}{5}{figure.caption.9}\protected@file@percent }
\newlabel{fig:unet}{{2.2}{5}{Schematic illustration of the U-Net architecture for image segmentation. The network consists of a contracting path (left side) to capture context via successive convolutional (3×3, ReLU) and max pooling (2×2) operations, and an expansive path (right side) that enables precise localization through up-convolutions (2×2) and concatenation with high-resolution features from the contracting path. The final segmentation map is generated using a 1×1 convolution. Feature map sizes and channel numbers are indicated for each layer}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Image Segmentation}{6}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Semantic and Instance Segmentation}{6}{subsection.2.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Semantic Segmentation in the Traffic Environment using the DeepLabv3+ Model}}{6}{figure.caption.10}\protected@file@percent }
\newlabel{fig:semanticSeg}{{2.3}{6}{Semantic Segmentation in the Traffic Environment using the DeepLabv3+ Model}{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Different instance segmentation methods, A: original image, B: Bottom-up approach, C: Top-down approach, D: Direct instance segmentation, where the model predicts instance-specific features that are used to delineate individual objects.}}{7}{figure.caption.11}\protected@file@percent }
\newlabel{fig:StarDist}{{2.4}{7}{Different instance segmentation methods, A: original image, B: Bottom-up approach, C: Top-down approach, D: Direct instance segmentation, where the model predicts instance-specific features that are used to delineate individual objects}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Cellpose}{7}{subsection.2.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces t-SNE embeddings of image styles from cellpose pretraining data.}}{8}{figure.caption.12}\protected@file@percent }
\newlabel{fig:cellpose_learning_objective}{{2.5}{8}{t-SNE embeddings of image styles from cellpose pretraining data}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Loss Functions and Metrics}{8}{subsection.2.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces t-SNE embedding of image styles from cellpose pretraining data.}}{9}{figure.caption.13}\protected@file@percent }
\newlabel{fig:t-SNE}{{2.6}{9}{t-SNE embedding of image styles from cellpose pretraining data}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Foundation Models}{10}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Transformer}{10}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}The Attention Mechanism}{11}{subsection.2.4.1}\protected@file@percent }
\newlabel{Eq:2.1}{{2.1}{11}{The Attention Mechanism}{equation.2.4.1}{}}
\newlabel{Eq:2.2}{{2.2}{11}{The Attention Mechanism}{equation.2.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Encoder self-attention for a set of reference points. The encoder is able to separate individual instances (A-D). }}{12}{figure.caption.14}\protected@file@percent }
\newlabel{fig:attention}{{2.7}{12}{Encoder self-attention for a set of reference points. The encoder is able to separate individual instances (A-D)}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Transformer}{12}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Vision Transformer}{12}{subsection.2.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Transformer architecture. For vision tasks, usually the left part (encoder) is taken.}}{13}{figure.caption.15}\protected@file@percent }
\newlabel{fig:transformer}{{2.8}{13}{Transformer architecture. For vision tasks, usually the left part (encoder) is taken}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}SegFormer}{13}{subsection.2.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Vision transformer as presented in }}{14}{figure.caption.16}\protected@file@percent }
\newlabel{fig:vit}{{2.9}{14}{Vision transformer as presented in}{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces SegFormer architecture as presented in}}{14}{figure.caption.17}\protected@file@percent }
\newlabel{fig:segformer}{{2.10}{14}{SegFormer architecture as presented in}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.5}MA-Net: Multi-Scale Attention Network}{15}{subsection.2.4.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Architecture of the MA-Net. }}{15}{figure.caption.18}\protected@file@percent }
\newlabel{fig:MAnet}{{2.11}{15}{Architecture of the MA-Net}{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Low-level view of the PAB block.}}{16}{figure.caption.19}\protected@file@percent }
\newlabel{fig:PAB}{{2.12}{16}{Low-level view of the PAB block}{figure.caption.19}{}}
\citation{LeCun.1989}
\citation{LeCun.1989}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Multi-scale Fusion Attention Block (MFAB) structure. }}{17}{figure.caption.20}\protected@file@percent }
\newlabel{fig:MFAB}{{2.13}{17}{Multi-scale Fusion Attention Block (MFAB) structure}{figure.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Masked Autoencoders}{17}{section.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces MAE architecture as presented in \cite  {LeCun.1989}.}}{18}{figure.caption.21}\protected@file@percent }
\newlabel{fig:MAE}{{2.14}{18}{MAE architecture as presented in \cite {LeCun.1989}}{figure.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Segment Anything}{18}{section.2.6}\protected@file@percent }
\citation{LeCun.1989}
\citation{LeCun.1989}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces MAE architecture as presented in \cite  {LeCun.1989}.}}{19}{figure.caption.22}\protected@file@percent }
\newlabel{fig:SAM1}{{2.15}{19}{MAE architecture as presented in \cite {LeCun.1989}}{figure.caption.22}{}}
\citation{LeCun.1989}
\citation{LeCun.1989}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Segment Anything 2}{20}{subsection.2.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}Hiera}{20}{subsection.2.6.2}\protected@file@percent }
\citation{caruana}
\citation{LeCun.1989}
\citation{LeCun.1989}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces MAE architecture as presented in \cite  {LeCun.1989}.}}{21}{figure.caption.23}\protected@file@percent }
\newlabel{fig:Hiera}{{2.16}{21}{MAE architecture as presented in \cite {LeCun.1989}}{figure.caption.23}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Mediar}{21}{section.2.7}\protected@file@percent }
\citation{LeCun.1989}
\citation{LeCun.1989}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces Encoder embeddings of the train set clustered with k-mean and intuition of amlplified sampling \cite  {LeCun.1989}.}}{22}{figure.caption.24}\protected@file@percent }
\newlabel{fig:mediar_net}{{2.17}{22}{Encoder embeddings of the train set clustered with k-mean and intuition of amlplified sampling \cite {LeCun.1989}}{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.18}{\ignorespaces Encoder embeddings of the train set clustered with k-mean and intuition of amlplified sampling \cite  {LeCun.1989}.}}{23}{figure.caption.25}\protected@file@percent }
\newlabel{fig:latent_modalities}{{2.18}{23}{Encoder embeddings of the train set clustered with k-mean and intuition of amlplified sampling \cite {LeCun.1989}}{figure.caption.25}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}CellposeSAM}{23}{section.2.8}\protected@file@percent }
\citation{LeCun.1989}
\citation{LeCun.1989}
\@writefile{lof}{\contentsline {figure}{\numberline {2.19}{\ignorespaces Encoder embeddings of the train set clustered with k-mean and intuition of amlplified sampling \cite  {LeCun.1989}.}}{24}{figure.caption.26}\protected@file@percent }
\newlabel{fig:cellposesam}{{2.19}{24}{Encoder embeddings of the train set clustered with k-mean and intuition of amlplified sampling \cite {LeCun.1989}}{figure.caption.26}{}}
\@setckpt{Chapters/020_sota}{
\setcounter{page}{25}
\setcounter{equation}{4}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{8}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{19}
\setcounter{table}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{KVtest}{0}
\setcounter{subfigure}{0}
\setcounter{subfigure@save}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{subtable@save}{0}
\setcounter{lotdepth}{1}
\setcounter{lstnumber}{1}
\setcounter{float@type}{16}
\setcounter{listing}{0}
\setcounter{lstdepth}{1}
\setcounter{parentequation}{0}
\setcounter{tabularnote}{0}
\setcounter{nicematrix_draft}{0}
\setcounter{section@level}{1}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{0}
\setcounter{lstlisting}{0}
}
